@startuml UML_FaceTTS

class pl.Trainer {
    gpus
    num_nodes
    strategy
    max_steps
    callbacks
    accumulate_grad_batches
    log_every_n_steps
    flush_logs_every_n_steps
    weights_summary
    val_check_interval
    fit(model, datamodule, ckpt_path)
    test(model, datamodule, ckpt_path)
}

class pl.callbacks.ModelCheckpoint {
    save_top_k
    verbose
    monitor
    mode
    save_last
    auto_insert_metric_name
}

class pl.callbacks.LearningRateMonitor {
    logging_interval
}

class pl.callbacks.ModelSummary {
    max_depth
}

class PosEmbedding {
    - dim
    + __init__(dim)
    + forward(x, scale=1000)
}

class GradLogPEstimator2d {
    - dim
    - dim_mults
    - groups
    - multi_spks
    - spk_emb_dim
    - pe_scale
    - spk_mlp: nn.Sequential
    - time_pos_emb: PosEmbedding
    - mlp: nn.Sequential
    - downs: nn.ModuleList
    - ups: nn.ModuleList
    - mid_block1: ResnetBlock
    - mid_attn: Residual
    - mid_block2: ResnetBlock
    - final_block: Block
    - final_conv: nn.Conv2d
    + __init__(dim, dim_mults=(1, 2, 4), groups=8, multi_spks=1, spk_emb_dim=512, n_feats=80, pe_scale=1000)
    + forward(x, mask, mu, t, spk=None)
}

class Diffusion {
    - n_feats
    - dim
    - multi_spks
    - spk_emb_dim
    - beta_min
    - beta_max
    - pe_scale
    - config
    - estimator: GradLogPEstimator2d
    + __init__(n_feats, dim, multi_spks=1, spk_emb_dim=512, beta_min=0.05, beta_max=20, pe_scale=1000, config=dict())
    + get_noise(t, beta_init, beta_term, cumulative=False)
    + forward_diff(x0, mask, mu, t)
    + reverse_diff(z, mask, mu, n_steps, stoc=False, spk=None)
    + forward(z, mask, mu, n_steps, stoc=False, spk=None)
    + loss_t(x0, mask, mu, t, spk=None)
    + compute_loss(x0, mask, mu, spk=None, offset=1e-5)
}

class SyncNet {
    - criterion: nn.CrossEntropyLoss
    - wI: nn.Parameter
    - bI: nn.Parameter
    - stride
    - nOut
    - netcnnaud: nn.Sequential
    - netfcaud: nn.Sequential
    - netcnnimg: nn.Sequential
    - netfcimg: nn.Sequential
    - config
    + __init__(config)
    + loadparameters(ckpt_path)
    + forward_aud(aud)
    + forward_vid(vid)
    + forward(vid, aud)
    + forward_perceptual(aud)
}

class ResnetBlock {
    + __init__(dim, dim_out, time_emb_dim)
}

class Residual {
    + __init__(fn)
}

class Block {
    + __init__(dim, dim_out, groups=8)
}

class Mish {
}

class Upsample {
    - conv: nn.ConvTranspose2d
}

class Downsample {
    - conv: nn.Conv2d
}

class Rezero {
    - fn
    - g: nn.Parameter
}

class LinearAttention {
    + __init__(dim, heads=4, dim_head=32)
}

class FFN {
    + __init__(in_channels, out_channels, filter_channels, kernel_size, p_dropout=0.0)
}

class MultiHeadAttention {
    + __init__(channels, out_channels, n_heads, window_size=None, heads_share=True, p_dropout=0.0, proximal_bias=False, proximal_init=False)
}

class LayerNorm {
    + __init__(channels, eps=1e-4)
}

class ConvReluNorm {
    + __init__(in_channels, hidden_channels, out_channels, kernel_size, n_layers, p_dropout)
}

class DurationPredictor {
    + __init__(in_channels, filter_channels, kernel_size, p_dropout)
}

class Encoder {
    + __init__(hidden_channels, filter_channels, n_heads, n_layers, kernel_size=1, p_dropout=0.0, window_size=None, **kwargs)
}

class TextEncoder {
    + __init__(n_vocab, n_feats, n_channels, filter_channels, filter_channels_dp, n_heads, n_layers, kernel_size, p_dropout, window_size=None, spk_emb_dim=512, multi_spks=1)
}

class SequenceUtils {
    + sequence_mask(length, max_length=None)
    + fix_len_compatibility(length, num_downsamplings_in_unet=2)
    + convert_pad_shape(pad_shape)
    + generate_path(duration, mask)
    + duration_loss(logw, logw_, lengths)
}

pl.LightningModule <|-- LayerNorm
pl.LightningModule <|-- ConvReluNorm
pl.LightningModule <|-- DurationPredictor
pl.LightningModule <|-- MultiHeadAttention
pl.LightningModule <|-- FFN
pl.LightningModule <|-- Encoder
pl.LightningModule <|-- TextEncoder

Mish --|> pl.LightningModule
Upsample --|> pl.LightningModule
Downsample --|> pl.LightningModule
Rezero --|> pl.LightningModule
Block --|> pl.LightningModule
ResnetBlock --|> pl.LightningModule
LinearAttention --|> pl.LightningModule
Residual --|> pl.LightningModule
SequenceUtils --> torch


class pl.LightningDataModule {
    setup
    dataset_cls
    dataset_name
    set_train_dataset
    set_val_dataset
    set_test_dataset
    load_dataloader
    train_dataloader
    val_dataloader
    test_dataloader
}

class LRS3Dataset {
    - split
    - config
    - cmudict
    - filelist
    - video_dir
    - audio_dir
    - data_list
    - spk_list
    + __init__(split: str = "", config=None)
    + __len__()
    + __getitem__(index)
    + loadtext(text, cmudict, add_blank=True)
    + load_random_frame(datadir, filename, len_frame=1)
}

class TextMelVideoBatchCollate {
    + __call__(self, batch)
}

class SequenceUtils {
    + sequence_mask(length, max_length=None)
    + fix_len_compatibility(length, num_downsamplings_in_unet=2)
    + convert_pad_shape(pad_shape)
    + generate_path(duration, mask)
    + duration_loss(logw, logw_, lengths)
}

pl.LightningDataModule <|-- LRS3DataModule
LRS3DataModule --> LRS3Dataset
LRS3DataModule --> TextMelVideoBatchCollate
LRS3DataModule --> SequenceUtils

pl.LightningDataModule <|-- LRS3DataModule
LRS3DataModule --> LRS3Dataset
LRS3DataModule --> TextMelVideoBatchCollate
LRS3DataModule --> SequenceUtils

pl.callbacks.ModelCheckpoint <-- LRS3DataModule
pl.callbacks.LearningRateMonitor <-- LRS3DataModule
pl.callbacks.ModelSummary <-- LRS3DataModule

class Extractor {
    - videopath
    - audiopath
    + extractData(videopath, audiopath=ModuleNotFoundError)
    + dataProcessing(videoroot, audioroot=None, listname='pretrain.list')
    + main()
    + expand_abbreviations(text)
    + expand_numbers(text)
    + lowercase(text)
    + collapse_whitespace(text)
    + convert_to_ascii(text)
    + basic_cleaners(text)
    + transliteration_cleaners(text)
    + english_cleaners(text)
}

Extractor --> SequenceUtils

class CMUDict {
    - _entries: Dict[str, List[str]]
    + __init__(file_or_path, keep_ambiguous=True)
    + __len__()
    + lookup(word)
}

CMUDict --> _parse_cmudict
CMUDict --> _get_pronunciation

class Symbols {
    - _pad: str
    - _punctuation: str
    - _special: str
    - _letters: str
    - _arpabet: List[str]
    - symbols: List[str]
}
Mish --|> pl.LightningModule
Upsample --|> pl.LightningModule
Downsample --|> pl.LightningModule
Rezero --|> pl.LightningModule
Block --|> pl.LightningModule
ResnetBlock --|> pl.LightningModule
LinearAttention --|> pl.LightningModule
Residual --|> pl.LightningModule
SequenceUtils --> torch
Trainer --> ModelCheckpoint
Trainer --> LearningRateMonitor
Trainer --> ModelSummary

class SpectrogramModule {
    + mel_basis: Dict[str, torch.Tensor]
    + hann_window: Dict[str, torch.Tensor]
    + __init__()
    + mel_spectrogram()
    + spectral_normalize_torch()
    + spectral_de_normalize_torch()
}

class TorchFunctions {
    + load_wav()
    + dynamic_range_compression_torch()
    + dynamic_range_decompression_torch()
}

TorchFunctions --> SpectrogramModule

class OptimizerModule {
    + set_scheduler(pl_module)
}

class AdamW {
    + __init__(params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0)
}

class Adam {
    + __init__(params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0)
}

class SGD {
    + __init__(params, lr, momentum=0, dampening=0, weight_decay=0, nesterov=False)
}

class SchedulerModule {
    + get_constant_schedule(optimizer)
    + get_polynomial_decay_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, lr_end, power)
    + get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)
    + get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)
}

OptimizerModule --> AdamW
OptimizerModule --> Adam
OptimizerModule --> SGD
OptimizerModule --> SchedulerModule

class FileUtility {
    + intersperse(lst, item)
    + parse_filelist(filelist_path, split_char="|")
    + latest_checkpoint_path(dir_path, regex="grad_*.pt")
    + load_checkpoint(logdir, model, num=None)
}

class VisualizationUtility {
    + save_figure_to_numpy(fig)
    + plot_tensor(tensor)
    + save_plot(tensor, savepath)
}

FileUtility --> VisualizationUtility
class DataLoader {
    + load_data(folder_path)
}

class SyncNetExperiment {
    - model: SyncNet
    - folder_path: str
    - num_iterations: int
    - device: torch.device
    - results: List[float]
    + __init__(folder_path, num_iterations, device)
    + run_experiment()
    - preprocess_image(image_path)
    - preprocess_audio(audio_path)
    - compute_accuracy(images, audios)
}

DataLoader --> SyncNetExperiment

class ConfigLoader {
    + load_config()
}

ConfigLoader --> SyncNetExperiment
class ConfigLoader {
    + load_config()
    + load_tts_model_config()
}

ConfigLoader --> SyncNetExperiment
ConfigLoader --> FaceTTSExperiment

class FaceTTSExperiment {
    + __init__(config)
    + train()
    + test()
}

FaceTTSExperiment --> ConfigLoader
@enduml